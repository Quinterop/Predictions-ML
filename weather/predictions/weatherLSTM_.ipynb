{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objs as go\n",
    "import plotly.express as px\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM, InputLayer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import explained_variance_score\n",
    "from sklearn.metrics import max_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.metrics import median_absolute_error\n",
    "from sklearn.metrics import mean_poisson_deviance\n",
    "from sklearn.metrics import mean_gamma_deviance\n",
    "from sklearn.metrics import mean_tweedie_deviance\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../NormalizedWeatherDataD.csv',sep=';')\n",
    "data.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rows are : Date\tType de tendance barométrique\tVitesse du vent moyen 10 mn\tHumidité\tVariation de pression en 24 heures\tRafale sur les 10 dernières minutes\tPrécipitations dans les 24 dernières heures\tTempérature (°C)\tLatitude\tLongitude\tAltitude\n",
    "\n",
    "#plot matrix\n",
    "fig = px.scatter_matrix(data, dimensions=[\"Vitesse du vent moyen 10 mn\", \"Humidité\", \"Variation de pression en 24 heures\", \"Rafale sur les 10 dernières minutes\", \"Précipitations dans les 24 dernières heures\", \"Température (°C)\"], color=\"Type de tendance barométrique\")\n",
    "#bigger\n",
    "fig.update_layout(\n",
    "    autosize=False,\n",
    "    width=2000,\n",
    "    height=2000,\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly.subplots import make_subplots\n",
    "\n",
    "#plot every row depending on time in separate graphs\n",
    "# color depending on density\n",
    "date = data['Date'].tolist()\n",
    "\n",
    "# for i in range(1, len(data.columns)):\n",
    "#     fig = go.Figure()\n",
    "    \n",
    "#     # Add line plot trace to subplot 1\n",
    "#     fig.add_trace(go.Scatter(x=date, y=data[data.columns[i]].tolist(), mode='lines', name=data.columns[i]), row=1, col=1)\n",
    "    \n",
    "#     # Add density mapbox trace to subplot 2\n",
    "#     fig.add_trace(go.Densitymapbox(\n",
    "#         lat=data[\"Date\"],\n",
    "#         lon=data[data.columns[i]],\n",
    "#         radius=10\n",
    "#     ), row=1, col=2)\n",
    "    \n",
    "#     # Update layout\n",
    "#     fig.update_layout(\n",
    "#         autosize=False,\n",
    "#         width=800,\n",
    "#         height=300,\n",
    "#         grid=dict(rows=1, columns=2, xgap=0.1, subplot_titles=('Line plot', 'Density map')),\n",
    "#         mapbox=dict(\n",
    "#             style='carto-positron',\n",
    "#             center=dict(lon=-95, lat=38),\n",
    "#             zoom=3,\n",
    "#         )\n",
    "#     )\n",
    "    \n",
    "    # fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, len(data.columns)):\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scatter(x=data['Date'], y=data\n",
    "    [data.columns[i]], mode='lines', name=data.columns[i]))\n",
    "    density = go.Densitymapbox(\n",
    "        lat=data[\"Date\"],\n",
    "        lon=data[data.columns[i]],\n",
    "        radius=10\n",
    "    )\n",
    "    fig.add_trace(density)\n",
    "    fig.update_layout(title=data.columns[i], xaxis_title='Date', yaxis_title=data.columns[i])\n",
    "\n",
    "    fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# données floues, séparer par zone géo ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot each feature relation with the temperature in different plots \n",
    "fig = px.scatter(data, x=\"Vitesse du vent moyen 10 mn\", y=\"Température (°C)\", color=\"Type de tendance barométrique\")\n",
    "fig.show()\n",
    "fig = px.scatter(data, x=\"Humidité\", y=\"Température (°C)\", color=\"Type de tendance barométrique\")\n",
    "fig.show()\n",
    "fig = px.scatter(data, x=\"Variation de pression en 24 heures\", y=\"Température (°C)\", color=\"Type de tendance barométrique\") \n",
    "fig.show()\n",
    "fig = px.scatter(data, x=\"Rafale sur les 10 dernières minutes\", y=\"Température (°C)\", color=\"Type de tendance barométrique\")\n",
    "fig.show()\n",
    "fig = px.scatter(data, x=\"Précipitations dans les 24 dernières heures\", y=\"Température (°C)\", color=\"Type de tendance barométrique\")\n",
    "fig.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate the most correlated features with the temperature\n",
    "corr = data.corr()\n",
    "corr.style.background_gradient(cmap='coolwarm')\n",
    "print(corr)\n",
    "#plot the most correlated features with the temperature\n",
    "fig = px.scatter(data, x=\"Vitesse du vent moyen 10 mn\", y=\"Température (°C)\", color=\"Type de tendance barométrique\")\n",
    "fig.show()\n",
    "fig = px.scatter(data, x=\"Humidité\", y=\"Température (°C)\", color=\"Type de tendance barométrique\")\n",
    "fig.show()\n",
    "\n",
    "print('the most influencial features are : Vitesse du vent moyen 10 mn and Humidité')\n",
    "\n",
    "#plot all correlations\n",
    "\n",
    "fig = px.imshow(corr)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# corrélations nulles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#linear regression\n",
    "print(data)\n",
    "X = data.drop(['Température (°C)'], axis=1)\n",
    "Y = data['Température (°C)']\n",
    "\n",
    "X = sm.add_constant(X)\n",
    "model = sm.OLS(Y, X).fit()\n",
    "\n",
    "# print the results\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test how much a result depends on the last result time wise\n",
    "# the more the result depends on the last result the more the result is time dependent\n",
    "# the more the result is time dependent the more the result is not a good predictor\n",
    "corr = data['Température (°C)'].corr(data['Température (°C)'].shift())\n",
    "print(\"Correlation coefficient between consecutive temperature values:\", corr)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# grosse corrélation consécutive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trying lstm\n",
    "#split the data into chunks of 5 for the input and 1 for the output\n",
    "#the output is the temperature of the next day\n",
    "\n",
    "# def split_sequence(sequence, n_steps_in, n_steps_out):\n",
    "#     X, y = list(), list()\n",
    "#     for i in range(len(sequence)):\n",
    "#         # find the end of this pattern\n",
    "#         end_ix = i + n_steps_in\n",
    "#         out_end_ix = end_ix + n_steps_out\n",
    "#         # check if we are beyond the sequence\n",
    "#         if out_end_ix > len(sequence):\n",
    "#             break\n",
    "#         # gather input and output parts of the pattern\n",
    "#         seq_x, seq_y = sequence[i:end_ix, :-1], sequence[end_ix:out_end_ix, -1]\n",
    "#         X.append(seq_x)\n",
    "#         y.append(seq_y)\n",
    "#     return np.array(X), np.array(y) \n",
    "\n",
    "def df_to_X_y(df, window_size=5):\n",
    "  df_as_np = df.to_numpy()\n",
    "  X = []\n",
    "  y = []\n",
    "  for i in range(len(df_as_np)-window_size):\n",
    "    row = [[a] for a in df_as_np[i:i+window_size]]\n",
    "    X.append(row)\n",
    "    label = df_as_np[i+window_size]\n",
    "    y.append(label)\n",
    "  return np.array(X), np.array(y)\n",
    "\n",
    "# split into samples\n",
    "n_steps_in= 5\n",
    "\n",
    "X1, y1 = df_to_X_y(Y, n_steps_in)\n",
    "print(X1.shape, y1.shape)\n",
    "\n",
    "# split into train and test sets\n",
    "X_train1, y_train1 = X1[:60000], y1[:60000]\n",
    "X_val1, y_val1 = X1[60000:65000], y1[60000:65000]\n",
    "X_test1, y_test1 = X1[65000:], y1[65000:]\n",
    "X_train1.shape, y_train1.shape, X_val1.shape, y_val1.shape, X_test1.shape, y_test1.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(InputLayer(input_shape=(5,1)))\n",
    "model.add(LSTM(64))\n",
    "model.add(Dense(8,'relu'))\n",
    "model.add(Dense(1,'linear'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "#edit adam learning rate ?\n",
    "#default adam learning rate is 0.001\n",
    "#edit adam learning rate to 0.0001 ?\n",
    "\n",
    "cp  = ModelCheckpoint(filepath='model.h5', save_best_only=True, verbose=0)\n",
    "model.fit(X_train1, y_train1, epochs=15,  validation_data=(X_test1, y_test1), callbacks=[cp])\n",
    "model = keras.models.load_model('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predictions = model.predict(X_train1).flatten()\n",
    "train_results = pd.DataFrame({'Actual': y_train1.flatten(), 'Predicted': train_predictions})\n",
    "print(train_results)\n",
    "\n",
    "#get r2 score\n",
    "print('r2 score : ', r2_score(y_train1, train_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot predictions and actual value depending on the time\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=data['Date'][:60000], y=train_results['Actual'], mode='lines', name='Actual'))\n",
    "fig.add_trace(go.Scatter(x=data['Date'][:60000], y=train_results['Predicted'], mode='lines', name='Predicted'))\n",
    "fig.update_layout(title='Actual and Predicted values', xaxis_title='Date', yaxis_title='Temperature')\n",
    "fig.show()\n",
    "\n",
    "\n",
    "#plot en nuage de points avec température par le temps   \n",
    "fig = px.scatter(train_results, x=data['Date'][:60000], y=\"Actual\", color=\"Predicted\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#same lstm network with multiple inputs\n",
    "#split the data into chunks of 5 for the input and 1 for the output\n",
    "# split the data into chunks of 5 for the input and 1 for the output\n",
    "# the output is the temperature of the next day\n",
    "def df_to_X_y(df, window_size=5):\n",
    "    df_as_np = df.to_numpy()\n",
    "    X = []\n",
    "    y = []\n",
    "    for i in range(len(df_as_np)-window_size):\n",
    "        row = [a for a in df_as_np[i:i+window_size]]\n",
    "        X.append(row)\n",
    "        label = df_as_np[i+window_size, 7] # only use the temperature column as label\n",
    "        y.append(label)\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# split into samples\n",
    "n_steps_in= 32\n",
    "\n",
    "X2, y2 = df_to_X_y(data, n_steps_in)\n",
    "print(X2.shape, y2.shape) \n",
    "\n",
    "\n",
    "# split into train and test sets\n",
    "X_train2, y_train2 = X2[:60000], y2[:60000]\n",
    "X_val2, y_val2 = X2[60000:65000], y2[60000:65000]\n",
    "X_test2, y_test2 = X2[65000:], y2[65000:]\n",
    "print(X_train2.shape, y_train2.shape, X_val2.shape, y_val2.shape, X_test2.shape, y_test2.shape)\n",
    "\n",
    "# define model\n",
    "input_shape = (X_train2.shape[1], X_train2.shape[2])\n",
    "model = Sequential()\n",
    "model.add(InputLayer(input_shape=input_shape))\n",
    "model.add(LSTM(units=64))\n",
    "model.add(Dense(units=8, activation='relu'))\n",
    "model.add(Dense(units=1, activation='linear'))\n",
    "\n",
    "adamrate = 0.01\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "# define callbacks\n",
    "cp  = ModelCheckpoint(filepath='model2.h5', save_best_only=True, verbose=0)\n",
    "\n",
    "# train the model\n",
    "model.fit(X_train2, y_train2, epochs=20, validation_data=(X_test2, y_test2), callbacks=[cp])\n",
    "\n",
    "# load the best model and evaluate on test set\n",
    "model = keras.models.load_model('model2.h5')\n",
    "test_predictions = model.predict(X_test2).flatten()\n",
    "test_results = pd.DataFrame({'Actual': y_test2.flatten(), 'Predicted': test_predictions})\n",
    "print(test_results)\n",
    "print('r2 score : ', r2_score(y_test2, test_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output the 8 next temperatures with the temp of the 8 previous days\n",
    "learning_days = 8\n",
    "X3, y3 = df_to_X_y(data,learning_days*8)\n",
    "X3_train, X3_test, y3_train, y3_test = train_test_split(X3, y3, test_size=0.2, random_state=42)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(InputLayer(input_shape=(X3_train.shape[1], X3_train.shape[2]))) #VERIFIER\n",
    "model.add(LSTM(units=64))\n",
    "model.add(Dense(units=8, activation='relu'))    \n",
    "model.add(Dense(units=1, activation='linear'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "model.fit(X3_train, y3_train, epochs=1, batch_size=72, verbose=2)\n",
    "\n",
    "\n",
    "# Generate the next X predictions\n",
    "n_predictions = X[-1:]  # Use the last sequence as initial input\n",
    "next_predictions = []\n",
    "for _ in range(X.shape[0]):\n",
    "    prediction = model.predict(n_predictions)\n",
    "    next_predictions.append(prediction)\n",
    "    n_predictions = np.concatenate([n_predictions[:, 1:, :], prediction[:, np.newaxis, :]], axis=1)\n",
    "\n",
    "\n",
    "# Print the next X predictions\n",
    "for i, prediction in enumerate(next_predictions, 1):\n",
    "    print(f\"Prediction {i}: {prediction[0]}\")\n",
    "\n",
    "#print r2 score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
