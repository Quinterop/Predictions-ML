{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import datetime\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "from datetime import timedelta\n",
    "\n",
    "\n",
    "def interpolation(X1,X2,Y1,Y2,XInconnu):\n",
    "    #prevent division by 0\n",
    "    if(X2 == X1):\n",
    "        return Y1\n",
    "    YInconnu = Y2*((XInconnu-X1)/(X2-X1))+Y1*((X2-XInconnu)/(X2-X1))\n",
    "    return YInconnu\n",
    "\n",
    "# def interpolation2(X1,X2,Y1,Y2,XInconnu):\n",
    "#     X = pd.Index(df['total_seconds'])\n",
    "#     Y = pd.Index(df['tmoy'])\n",
    "\n",
    "#      \n",
    "\n",
    "#     print(\"Value of X\")\n",
    "#     print(X)\n",
    "#     print(np.asarray(X).shape)\n",
    "\n",
    "#      \n",
    "\n",
    "#     print(\"\\n value of Y\")\n",
    "#     print(Y)\n",
    "#     print(np.asarray(Y).shape)\n",
    "\n",
    "#     # test value => total_seconds\n",
    "#     interpolate_x = 43200\n",
    "#     print(interpolate_x)\n",
    "\n",
    "#     # Finding the interpolation\n",
    "#     y_interp = interp1d(X, Y)\n",
    "#     print(\"Value of Y at x = {} is\".format(interpolate_x), y_interp(interpolate_x))\n",
    "\n",
    "#      \n",
    "\n",
    "#     print( )\n",
    "#     print(interpolate_x)\n",
    "#     print(y_interp(interpolate_x))\n",
    "\n",
    "\n",
    "\n",
    "def interpol_line(line1:pd.core.series.Series, line2:pd.core.series.Series, col2:str, target:int, toInterpol:list[str]=[], toNotInterpol:list[str]=[])->pd.core.series.Series:\n",
    "    #col2 : colonne de temps \n",
    "    #target : temps de la nouvelle ligne\n",
    "    #les temps doivent être des int ou float, peu importe l'échelle\n",
    "\n",
    "    x1 = line1[col2]\n",
    "    x2 = line2[col2]\n",
    "    res = line1.copy()\n",
    "    for col in res.index:\n",
    "        res[col] = np.nan \n",
    "    res[col2] = target\n",
    "    # interpolate all ints in the lines except col2\n",
    "    for col in line1.index:\n",
    "        if(col != col2  ):\n",
    "            #check that col is numeric and not boolean\n",
    "            if(pd.api.types.is_numeric_dtype(line1[col]) and  not pd.api.types.is_bool_dtype(line1[col])):\n",
    "                if(col in toInterpol or col not in toNotInterpol):\n",
    "                    y1 = line1[col]\n",
    "                    y2 = line2[col]\n",
    "                    print(\"interpolating\", col, \"from\", y1, \"to\", y2, \"for\", target, \"between\", x1, \"and\", x2) \n",
    "                    print()\n",
    "                    res[col]=(interpolation(x1, x2, y1, y2, target))\n",
    "                    print(\"result\", res[col])\n",
    "    return res\n",
    "\n",
    "def normalize(val, min, max):\n",
    "    return (val-min)/(max-min)\n",
    "    #FIX : floating point error\n",
    "\n",
    "def denormalize(val, min, max):\n",
    "    return val*(max-min)+min\n",
    "\n",
    "def interpolDf(df, timecol, pas_voulu, offset=0, toInterpol:list[str]=[], toNotInterpol:list[str]=[]):\n",
    "    #la fonction recale un dataset sur une échelle de temps régulière\n",
    "\n",
    "    #df : dataframe à interpoler\n",
    "    #timecol : colonne de temps\n",
    "    #toInterpol : liste des colonnes à interpoler (facultatif)\n",
    "    #toNotInterpol : liste des colonnes à ne pas interpoler (facultatif)\n",
    "    #pas_voulu : pas voulu pour l'interpolation\n",
    "    #offset : décalage à appliquer à la colonne de temps\n",
    "    #les temps doivent être des int ou float, peu importe l'échelle\n",
    "  \n",
    "    #on trie le df par temps\n",
    "    df = df.sort_values(by=timecol)\n",
    "\n",
    "    #on récupère les temps min et max\n",
    "    min = df[timecol].min()\n",
    "    max = df[timecol].max() \n",
    "\n",
    "    #on normalise les temps et on arrondit a 5 chiffres après la virgule\n",
    "    df[timecol] = df[timecol].apply(lambda x: normalize(x, min, max))\n",
    "    df[timecol] = df[timecol].apply(lambda x: round(x, 5))\n",
    "\n",
    "    #on crée une colonne original pour marquer les lignes originales et une colonne filled pour marquer les lignes interpolables\n",
    "    df['original'] = True\n",
    "    df['filled'] = True\n",
    "\n",
    "\n",
    "    #on adapte le pas voulu et l'offset à la normalisation\n",
    "    pas_voulu = pas_voulu/(max-min)\n",
    "    offset = offset/(max-min)\n",
    "\n",
    "    #on crée une liste de temps à interpoler arrondis à 5 chiffres après la virgule\n",
    "    temps = np.arange(min + offset, 1, pas_voulu)\n",
    "    temps = [round(t, 5) for t in temps]\n",
    "\n",
    "    #on ajoute des lignes vides avec les temps à interpoler au df si elles n'existent pas déjà\n",
    "    for t in temps:  \n",
    "        if(t not in df[timecol].values): #warning penser a floating point error\n",
    "            newline = pd.Series([np.nan for i in range(len(df.columns))], index=df.columns)\n",
    "            newline[timecol] = t\n",
    "            newline['original'] = False \n",
    "            newline['filled'] = False\n",
    "            df = df.append(newline, ignore_index=True)\n",
    "        \n",
    "    \n",
    "    #on trie le df par temps\n",
    "    df = df.sort_values(by=timecol)\n",
    "    df = df.reset_index(drop=True)\n",
    "    print(df)\n",
    "    #on interpole les lignes vides\n",
    "    for i in range(len(df)):\n",
    "        if(df['filled'][i] == False):\n",
    "            #on récupère les lignes avant et après si elles existent\n",
    "    \n",
    "            line1 = None\n",
    "            line2 = None\n",
    "\n",
    "            #debug prints\n",
    "            \n",
    "\n",
    "            print()\n",
    "            print('finding line 2')\n",
    "            for j in range(i+1, len(df)):\n",
    "                # print('j',j)\n",
    "                # print('line j',df.iloc[j])\n",
    "                if(df['filled'][j] == True):\n",
    "                    line2 = df.iloc[j]\n",
    "                    print('line 2 found')\n",
    "                    break\n",
    "                # else:\n",
    "                #     print('line 2 NOT found')\n",
    "                    \n",
    "                    \n",
    "            for k in range(i-1, -1, -1):\n",
    "                # print('line at k',df.iloc[k])\n",
    "                if(df['filled'][k] == True):\n",
    "                    line1 = df.iloc[k]\n",
    "                    print('line 1 found')\n",
    "                    break\n",
    "                # else:\n",
    "                #     print('line 1 NOT found')\n",
    "                    \n",
    "                    \n",
    "\n",
    "            #on interpole la ligne vide\n",
    "            # print('LINE1',line1)\n",
    "            # print('LINE2',line2)\n",
    "            if(line1 is None or line2 is None):\n",
    "                print(\"error : no line before or after line at\", i)\n",
    "                continue\n",
    "            df.iloc[i] = interpol_line(line1, line2, timecol, df[timecol][i], toInterpol, toNotInterpol)\n",
    "            df['filled'][i] = True\n",
    "\n",
    "\n",
    "    #on dénormalise les temps\n",
    "    df[timecol] = df[timecol].apply(lambda x: denormalize(x, min, max))\n",
    "\n",
    "    #on supprime les lignes originales ?\n",
    "    # df = df[~df['original']]\n",
    "\n",
    "    #on supprime les colonne original et filled\n",
    "    df = df.drop(columns=['original'])\n",
    "    df = df.drop(columns=['filled'])\n",
    "\n",
    "\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def df_generate_int(t_start , t_end, period, T_fld_name ='date_time') :\n",
    "    #pour un entier en temps\n",
    "    times = []\n",
    "    for t in range(t_start, t_end, period):\n",
    "        times.append(t)\n",
    "    df = pd.DataFrame(times, columns=[T_fld_name])\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def df_generate_datetime(t_start , t_end, period, T_fld_name ='date_time') :\n",
    "    #pour un temps en format datetime\n",
    "\n",
    "    #on convertit tout en secondes\n",
    "    start = int(t_start.timestamp())\n",
    "    end = int(t_end.timestamp())\n",
    "    step = int(period.total_seconds())\n",
    "\n",
    "    times = []\n",
    "    for t in range (start, end, step):\n",
    "        times.append(t)\n",
    "\n",
    "    # create an empty list to store the UTC datetime objects\n",
    "    utc_times = []\n",
    "\n",
    "    # convert the timestamps to datetime objects in UTC timezone\n",
    "    for t in times:\n",
    "        utc_times.append(pd.to_datetime(t, unit='s', utc=True))\n",
    "\n",
    "    # create an empty list to store the Europe/Paris datetime objects\n",
    "    paris_times = []\n",
    "\n",
    "    # convert the UTC datetime objects to Europe/Paris timezone and remove the timezone information\n",
    "    for t in utc_times:\n",
    "        paris_time = t.astimezone(tz='Europe/Paris')\n",
    "        paris_time = paris_time.replace(tzinfo=None)\n",
    "        paris_times.append(paris_time)\n",
    "\n",
    "    df = pd.DataFrame(paris_times, columns=[T_fld_name])\n",
    "    return df\n",
    "\n",
    "#test \n",
    "# df = df_generate(0, 100, 1)\n",
    "# print(df)\n",
    "# df = df_generate_datetime(datetime.datetime(2021, 1, 1), datetime.datetime(2021, 1, 20, tzinfo=datetime.timezone.utc), timedelta(days=1))\n",
    "# print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_full(x):\n",
    "    pd.set_option('display.max_rows', len(x))\n",
    "    print(x)\n",
    "    pd.reset_option('display.max_rows')\n",
    "\n",
    "\n",
    "def df_interpolation(dataframe1, T_fld_name1, dataframe2, T_fld_name2, fld_name) :\n",
    "    # on prend 2 df complets, on ajoute la colonne fld_name a dataframe1 et on l'interpole en gardant les valeurs de dataframe2\n",
    "\n",
    "    # dataframe1 : données réelles\n",
    "    # T_fld_name1 : nom de la colonne de temps de dataframe1\n",
    "    # dataframe2 : df avec les temps et les données de  fld_name à interpoler\n",
    "    # T_fld_name2 : nom de la colonne de temps de dataframe2\n",
    "    # fld_name : nom de la colonne à insérer dans dataframe1\n",
    "\n",
    "\n",
    "    df = dataframe1.copy()\n",
    "\n",
    "    df2 = dataframe2[[T_fld_name2, fld_name]].copy()\n",
    "    \n",
    "    print('DATAFRAMES')\n",
    "    print(df)\n",
    "    print(df2)\n",
    "\n",
    "    if(fld_name in df.columns):\n",
    "        return df.merge(df2, how='left', left_on=T_fld_name1, right_on=T_fld_name2)\n",
    "    \n",
    "    df[fld_name] = np.NaN\n",
    "   \n",
    "    if(type(df[T_fld_name1][0]) != type(df2[T_fld_name2][0])):\n",
    "        print('error : different types of time')\n",
    "        return\n",
    "    \n",
    "    \n",
    "\n",
    "    #add all values of df2[T_fld_name2] to df[T_fld_name1] if they don't exist\n",
    "    # for row,index in df2.iterrows():\n",
    "    #     if(df2[T_fld_name2][row] not in df[T_fld_name1].values):\n",
    "    #         df.loc[len(df)] = [df2[T_fld_name2][row], np.NaN]\n",
    "    #         print('new value added to df : ', df2[T_fld_name2][row])\n",
    "             #BROKEN\n",
    "\n",
    "    # print('MERGED DATES')\n",
    "    # print(df)\n",
    "\n",
    "    df = df.sort_values(by=[T_fld_name1])\n",
    "    df = df.reset_index(drop=True)\n",
    "\n",
    "    if(T_fld_name1 != T_fld_name2):\n",
    "        df = df.drop(columns=[T_fld_name2])\n",
    "        \n",
    "    #on insere les valeurs de df2 dans df si le temps correspond\n",
    "    for row,index in df.iterrows():\n",
    "        bigdf2date = df2.loc[df2[T_fld_name2] == df[T_fld_name1][row]]\n",
    "        # print('df2date',bigdf2date)\n",
    "        # print()\n",
    "        # print(type(bigdf2date))\n",
    "        if(len(bigdf2date) == 0):\n",
    "            continue\n",
    "        df2date = bigdf2date.iloc[0]\n",
    "        # print('CHANGE')\n",
    "        # print('df2date',df2date)\n",
    "        # print()\n",
    "        # print(type(df2date))\n",
    "        df[fld_name][row] = df2date[fld_name]\n",
    "        # print('found matching date : ', df[T_fld_name1][row], 'value : ', df2date[fld_name])\n",
    "\n",
    "\n",
    "    # print_full(df)\n",
    "\n",
    "    \n",
    "    #on interpole les valeurs manquantes\n",
    "\n",
    "    for i in range(len(df)):\n",
    "        if(np.isnan(df[fld_name][i])):\n",
    "            #on récupère les lignes avant et après si elles existent\n",
    "    \n",
    "            line1 = None\n",
    "            line2 = None\n",
    "\n",
    "          \n",
    "            # print()\n",
    "            # print('finding lines')\n",
    "\n",
    "            for j in range(i+1, len(df)):\n",
    "                # print('j',j)\n",
    "                # print('j date and value',df.iloc[j][T_fld_name1], df.iloc[j][fld_name])\n",
    "                if(not np.isnan(df[fld_name][j])):\n",
    "                    line2 = df.iloc[j]\n",
    "                    # print('line 2 found')\n",
    "                    break\n",
    "                # else:\n",
    "                    # print('line 2 NOT found')\n",
    "                    \n",
    "                    \n",
    "            for k in range(i-1, -1, -1):\n",
    "                # print('line at k',df.iloc[k])\n",
    "                if(not np.isnan(df[fld_name][k])):\n",
    "                    line1 = df.iloc[k]\n",
    "                    # print('line 1 found')\n",
    "                    break\n",
    "                # else:\n",
    "                #     print('line 1 NOT -((ggg))')\n",
    "                    \n",
    "                    \n",
    "\n",
    "            #on interpole la ligne vide\n",
    "            # print('LINE1',line1)\n",
    "            # print('LINE2',line2)\n",
    "            if(line1 is None or line2 is None):\n",
    "                print(\"error : no line before or after line at\", i)\n",
    "                continue\n",
    "            # print(line1[fld_name])\n",
    "            # print(line2[fld_name])\n",
    "            # print(line1[T_fld_name1])\n",
    "            # print(line2[T_fld_name1])\n",
    "            # print(df[T_fld_name1][i])\n",
    "\n",
    "            #convert date strings to ints\n",
    "            if(type(line1[T_fld_name1]) == str):\n",
    "                timeline1 = datetime.datetime.strptime(line1[T_fld_name1], '%Y-%m-%d')\n",
    "            if(type(line2[T_fld_name1]) == str):\n",
    "               timeline2 = datetime.datetime.strptime(line2[T_fld_name1], '%Y-%m-%d')\n",
    "            if(type(df[T_fld_name1][i]) == str):\n",
    "                timelinedf = datetime.datetime.strptime(df[T_fld_name1][i], '%Y-%m-%d')\n",
    "\n",
    "            # print(line1[fld_name])\n",
    "            # print(line2[fld_name])\n",
    "            # print(timeline1)\n",
    "            # print(timeline2)\n",
    "            # print(timelinedf)\n",
    "\n",
    "            value = interpolation(timeline1, timeline2, line1[fld_name], line2[fld_name], timelinedf)\n",
    "                        # value = interpolation( line1[T_fld_name1], line2[T_fld_name1], line1[fld_name], line2[fld_name], df[T_fld_name1][i])\n",
    "\n",
    "            df[fld_name][i] = value\n",
    "            # print('line',i,'interpolated value :',value)\n",
    "        else:\n",
    "            pass\n",
    "            # print('line',i,'is not empty')\n",
    "            # print('value :',df[fld_name][i])\n",
    "    return df    \n",
    "\n",
    "# A TESTER\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATAFRAMES\n",
      "           date  wind  powergen\n",
      "0    2020-01-01     5      1666\n",
      "1    2020-01-02    10      3333\n",
      "2    2020-01-03    13      4300\n",
      "3    2020-01-04    28      9333\n",
      "4    2020-01-05    25      8333\n",
      "..          ...   ...       ...\n",
      "117  2020-04-27    18      6000\n",
      "118  2020-04-28     2       666\n",
      "119  2020-04-29     5      1666\n",
      "120  2020-04-30    22      7333\n",
      "121  2020-05-01     9      3000\n",
      "\n",
      "[122 rows x 3 columns]\n",
      "         date  temp\n",
      "0  2020-01-01     1\n",
      "1  2020-02-01    -4\n",
      "2  2020-03-01    12\n",
      "3  2020-04-01    18\n",
      "4  2020-05-01    20\n",
      "5  2021-01-01     2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AlassaneSY\\AppData\\Local\\Temp\\ipykernel_16580\\65157343.py:65: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[fld_name][row] = df2date[fld_name]\n",
      "C:\\Users\\AlassaneSY\\AppData\\Local\\Temp\\ipykernel_16580\\65157343.py:136: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[fld_name][i] = value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           date  wind  powergen       temp\n",
      "0    2020-01-01     5      1666   1.000000\n",
      "1    2020-01-02    10      3333   0.838710\n",
      "2    2020-01-03    13      4300   0.677419\n",
      "3    2020-01-04    28      9333   0.516129\n",
      "4    2020-01-05    25      8333   0.354839\n",
      "5    2020-01-06     4      1333   0.193548\n",
      "6    2020-01-07    27      9000   0.032258\n",
      "7    2020-01-08    20      6666  -0.129032\n",
      "8    2020-01-09    29      9666  -0.290323\n",
      "9    2020-01-10    11      3666  -0.451613\n",
      "10   2020-01-11    25      8333  -0.612903\n",
      "11   2020-01-12     5      1666  -0.774194\n",
      "12   2020-01-13    17      5666  -0.935484\n",
      "13   2020-01-14    27      9000  -1.096774\n",
      "14   2020-01-15    22      7333  -1.258065\n",
      "15   2020-01-16    28      9333  -1.419355\n",
      "16   2020-01-17     2       666  -1.580645\n",
      "17   2020-01-18     0         0  -1.741935\n",
      "18   2020-01-19    23      7666  -1.903226\n",
      "19   2020-01-20     1        33  -2.064516\n",
      "20   2020-01-21    17      5666  -2.225806\n",
      "21   2020-01-22    22      7333  -2.387097\n",
      "22   2020-01-23    28      9333  -2.548387\n",
      "23   2020-01-24    26      8666  -2.709677\n",
      "24   2020-01-25     5      1666  -2.870968\n",
      "25   2020-01-26     2       666  -3.032258\n",
      "26   2020-01-27     8      2666  -3.193548\n",
      "27   2020-01-28    13      4300  -3.354839\n",
      "28   2020-01-29    20      6666  -3.516129\n",
      "29   2020-01-30    22      7333  -3.677419\n",
      "30   2020-01-31    15      5000  -3.838710\n",
      "31   2020-02-01     8      2666  -4.000000\n",
      "32   2020-02-02     5      1666  -3.448276\n",
      "33   2020-02-03    16      5333  -2.896552\n",
      "34   2020-02-04     3      1000  -2.344828\n",
      "35   2020-02-05    23      7666  -1.793103\n",
      "36   2020-02-06    23      7666  -1.241379\n",
      "37   2020-02-07     1        33  -0.689655\n",
      "38   2020-02-08    26      8666  -0.137931\n",
      "39   2020-02-09    21      7000   0.413793\n",
      "40   2020-02-10    26      8666   0.965517\n",
      "41   2020-02-11    12      4000   1.517241\n",
      "42   2020-02-12     4      1333   2.068966\n",
      "43   2020-02-13    25      8333   2.620690\n",
      "44   2020-02-14     4      1333   3.172414\n",
      "45   2020-02-15    14      4666   3.724138\n",
      "46   2020-02-16     2       666   4.275862\n",
      "47   2020-02-17    10      3333   4.827586\n",
      "48   2020-02-18     0         0   5.379310\n",
      "49   2020-02-19    26      8666   5.931034\n",
      "50   2020-02-20    19      6333   6.482759\n",
      "51   2020-02-21    18      6000   7.034483\n",
      "52   2020-02-22    12      4000   7.586207\n",
      "53   2020-02-23    10      3333   8.137931\n",
      "54   2020-02-24    14      4666   8.689655\n",
      "55   2020-02-25    17      5666   9.241379\n",
      "56   2020-02-26    16      5333   9.793103\n",
      "57   2020-02-27    15      5000  10.344828\n",
      "58   2020-02-28    18      6000  10.896552\n",
      "59   2020-02-29    12      4000  11.448276\n",
      "60   2020-03-01     8      2666  12.000000\n",
      "61   2020-03-02     0         0  12.193548\n",
      "62   2020-03-03     6      2000  12.387097\n",
      "63   2020-03-04    20      6666  12.580645\n",
      "64   2020-03-05     2       666  12.774194\n",
      "65   2020-03-06     9      3000  12.967742\n",
      "66   2020-03-07    18      6000  13.161290\n",
      "67   2020-03-08    26      8666  13.354839\n",
      "68   2020-03-09     8      2666  13.548387\n",
      "69   2020-03-10    20      6666  13.741935\n",
      "70   2020-03-11    26      8666  13.935484\n",
      "71   2020-03-12     5      1666  14.129032\n",
      "72   2020-03-13     8      2666  14.322581\n",
      "73   2020-03-14    12      4000  14.516129\n",
      "74   2020-03-15    19      6333  14.709677\n",
      "75   2020-03-16    15      5000  14.903226\n",
      "76   2020-03-17    15      5000  15.096774\n",
      "77   2020-03-18    12      4000  15.290323\n",
      "78   2020-03-19    17      5666  15.483871\n",
      "79   2020-03-20    19      6333  15.677419\n",
      "80   2020-03-21    14      4666  15.870968\n",
      "81   2020-03-22     0         0  16.064516\n",
      "82   2020-03-23     3      1000  16.258065\n",
      "83   2020-03-24    21      7000  16.451613\n",
      "84   2020-03-25     5      1666  16.645161\n",
      "85   2020-03-26    29      9666  16.838710\n",
      "86   2020-03-27    17      5666  17.032258\n",
      "87   2020-03-28     9      3000  17.225806\n",
      "88   2020-03-29     7      2333  17.419355\n",
      "89   2020-03-30    28      9333  17.612903\n",
      "90   2020-03-31     5      1666  17.806452\n",
      "91   2020-04-01     2       666  18.000000\n",
      "92   2020-04-02    25      8333  18.066667\n",
      "93   2020-04-03     7      2333  18.133333\n",
      "94   2020-04-04    13      4300  18.200000\n",
      "95   2020-04-05     8      2666  18.266667\n",
      "96   2020-04-06    11      3666  18.333333\n",
      "97   2020-04-07     0         0  18.400000\n",
      "98   2020-04-08    22      7333  18.466667\n",
      "99   2020-04-09    28      9333  18.533333\n",
      "100  2020-04-10    17      5666  18.600000\n",
      "101  2020-04-11    17      5666  18.666667\n",
      "102  2020-04-12     9      3000  18.733333\n",
      "103  2020-04-13    11      3666  18.800000\n",
      "104  2020-04-14     4      1333  18.866667\n",
      "105  2020-04-15    12      4000  18.933333\n",
      "106  2020-04-16    29      9666  19.000000\n",
      "107  2020-04-17     1        33  19.066667\n",
      "108  2020-04-18     9      3000  19.133333\n",
      "109  2020-04-19    22      7333  19.200000\n",
      "110  2020-04-20    15      5000  19.266667\n",
      "111  2020-04-21    25      8333  19.333333\n",
      "112  2020-04-22     3      1000  19.400000\n",
      "113  2020-04-23    29      9666  19.466667\n",
      "114  2020-04-24    17      5666  19.533333\n",
      "115  2020-04-25    11      3666  19.600000\n",
      "116  2020-04-26    29      9666  19.666667\n",
      "117  2020-04-27    18      6000  19.733333\n",
      "118  2020-04-28     2       666  19.800000\n",
      "119  2020-04-29     5      1666  19.866667\n",
      "120  2020-04-30    22      7333  19.933333\n",
      "121  2020-05-01     9      3000  20.000000\n"
     ]
    }
   ],
   "source": [
    "#test\n",
    "df2 =  pd.read_csv('df1.csv')\n",
    "df1 =  pd.read_csv('df2.csv')\n",
    "df1.head()\n",
    "df2.head()\n",
    "\n",
    "dfres = df_interpolation(df1,'date',df2,'date','temp')\n",
    "print_full(dfres)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "da7c1f3699ef39dfc1389a9b1185f0b5f6d903e921e2912b1a56cc79254680c5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
